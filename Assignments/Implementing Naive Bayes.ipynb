{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.summaries = None\n",
    "    \n",
    "    def separate_by_class(self, dataset):\n",
    "        \"\"\"\n",
    "        This method allows us to separate the training data by classes.\n",
    "        A dictionary object maps each class value to list of all records\n",
    "        \"\"\"\n",
    "        \n",
    "        # initializes dict to map class values to a \n",
    "        separated = dict() \n",
    "        \n",
    "        # maps individual class values to a dataframe with matching class values\n",
    "        \"\"\"for class_value in dataset.iloc[:, -1].unique():\n",
    "            separated[class_value] = dataset.loc[ dataset.iloc[:, -1] == class_value]\"\"\"\n",
    "        \n",
    "        for i in range(len(dataset)):\n",
    "            vector = dataset[i]\n",
    "            class_value = vector[-1]\n",
    "            if class_value not in separated:\n",
    "                separated[class_value] = list()\n",
    "            separated[class_value].append(vector)\n",
    "                \n",
    "        return separated\n",
    "    \n",
    "   \n",
    "    def summarize_dataset(self, dataset):\n",
    "        \"\"\"\n",
    "        This method returns the important statistics for each column\n",
    "        in the dataset. These are mean, std and count. \n",
    "        \"\"\"\n",
    "        def _mean(numbers):\n",
    "            return sum(numbers) / float(len(numbers))\n",
    "        def _stdev(numbers):\n",
    "            from math import sqrt\n",
    "            avg = _mean(numbers)\n",
    "            variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers) - 1)\n",
    "            return sqrt(variance)\n",
    "        \n",
    "        # uses list comprehension to store tuples of important statistics for each column\n",
    "        # last column is class column and is not needed\n",
    "        summaries = [(_mean(column), _stdev(column), \n",
    "                      len(column)) for column in zip(*dataset)]\n",
    "        del(summaries[-1])\n",
    "        \n",
    "        return summaries\n",
    "    \n",
    "    \n",
    "    def fit(self, dataset):\n",
    "        \"\"\"\n",
    "        This method splits the dataset by class and calculates statistics for each\n",
    "        \"\"\"\n",
    "        # initializes a dict to map class values to a summary of their matching dataframes\n",
    "        summaries = dict()\n",
    "        \n",
    "        # separates dataset by class values \n",
    "        separated = self.separate_by_class(dataset)\n",
    "        \n",
    "        # calculates columns' statistics for each class value\n",
    "        for class_value, rows in separated.items():\n",
    "            summaries[class_value] = self.summarize_dataset(rows)\n",
    "            \n",
    "        self.summaries = summaries    \n",
    "   \n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        \"\"\"\n",
    "        This method calculates the Gaussian probability distribution function for x\n",
    "        \"\"\"\n",
    "        from math import exp\n",
    "        from math import pi\n",
    "        from math import sqrt \n",
    "        \n",
    "        # calculates exponent first for simplification\n",
    "        exponent = exp(-((x - mean) ** 2 / (2 * (stdev ** 2))))\n",
    "        return (1 / ( sqrt(2 * pi) * stdev)) * exponent\n",
    "    \n",
    "    \n",
    "    def calculate_class_probabilities(self, summaries, row):\n",
    "        \"\"\"\n",
    "        This method calculates the probabilites of each class for a given row\n",
    "        \"\"\"\n",
    "        \n",
    "        # finds total number of rows in entire dataset\n",
    "        total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "        \n",
    "        # initializes a dictionary to hold probabilities\n",
    "        probabilities = dict()\n",
    "        \n",
    "        # calculates probabilities \n",
    "        for class_value, class_summaries in summaries.items():\n",
    "            probabilities[class_value] = summaries[class_value][0][2] / float(total_rows)\n",
    "            for i in range(len(class_summaries)):\n",
    "                mean, stdev, _ = class_summaries[i]\n",
    "                probabilities[class_value] *= self.calculate_probability(row[i], mean, stdev)\n",
    "        return probabilities\n",
    "    \n",
    "    def _pred(self, summaries, row):\n",
    "            \"\"\"\n",
    "            This method predicts class for a given row\n",
    "            \"\"\"\n",
    "            probabilities = self.calculate_class_probabilities(self.summaries, row)\n",
    "            best_label, best_prob = None, -1\n",
    "            for class_value, probability in probabilities.items():\n",
    "                if best_label is None or probability > best_prob:\n",
    "                    best_prob = probability\n",
    "                    best_label = class_value\n",
    "            return best_label\n",
    "        \n",
    "    def predict(self, test):\n",
    "        \"\"\"\n",
    "        This method predicts class for a whole dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "            output = self._pred(self.summaries, row)\n",
    "            predictions.append(output)\n",
    "            \n",
    "        return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "    [3.582294042,4.67917911, 0],\n",
    "    [7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "    [7.939820817,0.791637231,1]]\n",
    "\n",
    "dataset2 = [[2.280362439,2.866990263],\n",
    "    [7.792783481,3.424088941]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayes()\n",
    "\n",
    "model.fit(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
