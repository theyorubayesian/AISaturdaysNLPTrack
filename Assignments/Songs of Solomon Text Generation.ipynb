{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_of_solomon = open(\".\\\\data\\\\Songs of Solomon Corpus.txt\", 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 13686 characters\n"
     ]
    }
   ],
   "source": [
    "print('Length of text: {} characters'.format(len(songs_of_solomon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1\n",
      "\n",
      "1 The Song of songs, which is Solomon's.\n",
      "Beloved\n",
      "2 Let him kiss me with the kisses of his mouth\n",
      "for your love is better than wine.\n",
      "3 Your oils have a pleasing fragrance.\n",
      "Your name is oil poured forth,\n",
      "therefore the virgins love you.\n",
      "4 Take\n"
     ]
    }
   ],
   "source": [
    "print(songs_of_solomon[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(songs_of_solomon))\n",
    "print('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in songs_of_solomon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Chapter 1\\n\\n1 The Song of songs, which is Solomon's\" ---- characters mapped to int ----> [19 47 40 55 59 44 57  1  7  0  0  7  1 35 47 44  1 34 54 53 46  1 54 45\n",
      "  1 58 54 53 46 58  4  1 62 47 48 42 47  1 48 58  1 34 54 51 54 52 54 53\n",
      "  3 58]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 50 characters from the text are mapped to integers\n",
    "print('{} ---- characters mapped to int ----> {}'.format(repr(songs_of_solomon[:50]), text_as_int[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "h\n",
      "a\n",
      "p\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(songs_of_solomon) // (seq_length + 1)\n",
    "\n",
    "# Create training examples/targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Chapter 1\\n\\n1 The Song of songs, which is Solomon's.\\nBeloved\\n2 Let him kiss me with the kisses of his \"\n",
      "'mouth\\nfor your love is better than wine.\\n3 Your oils have a pleasing fragrance.\\nYour name is oil pour'\n",
      "'ed forth,\\ntherefore the virgins love you.\\n4 Take me away with you.\\nLet us hurry.\\nThe king has brought'\n",
      "' me into his chambers.\\nFriends\\nWe will be glad and rejoice in you.\\nWe will praise your love more than'\n",
      "' wine!\\nBeloved\\nThey are right to love you.\\n5 I am dark, but lovely,\\nyou daughters of Jerusalem,\\nlike '\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate and shift sequence to form input and text\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"Chapter 1\\n\\n1 The Song of songs, which is Solomon's.\\nBeloved\\n2 Let him kiss me with the kisses of his\"\n",
      "Target data:  \"hapter 1\\n\\n1 The Song of songs, which is Solomon's.\\nBeloved\\n2 Let him kiss me with the kisses of his \"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((8, 100), (8, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True,\n",
    "                           stateful=True,\n",
    "                           recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size=len(vocab),\n",
    "                   embedding_dim=embedding_dim,\n",
    "                   rnn_units=rnn_units,\n",
    "                   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100, 68) # (batch_size, sequence_length, vocab_length)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_length)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (8, None, 256)            17408     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (8, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (8, None, 68)             69700     \n",
      "=================================================================\n",
      "Total params: 4,025,412\n",
      "Trainable params: 4,025,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 54, 57, 44, 17, 16, 64,  3, 49, 12, 42, 66, 22, 37, 40,  3, 28,\n",
       "       25, 12,  9, 27, 32,  8, 51, 26,  4,  9, 47, 41, 39, 58, 24, 44,  2,\n",
       "       38, 60, 35, 54, 51, 16, 32,  3,  7, 55, 25, 44, 43, 16, 10, 61, 41,\n",
       "       55, 43, 34, 25, 24, 37, 61,  6, 34, 51, 45, 29, 41, 57, 28, 57, 33,\n",
       "       65,  7, 38, 43, 13, 52, 32, 18, 10, 14, 27, 59, 35, 52, 39,  1, 42,\n",
       "        7,  2, 23, 31,  2, 29, 31, 58, 34,  8, 29,  2, 26, 21, 21],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'rh with my spice I have eaten my honeycomb with my honey I have drunk my wine with my milk.\\nFriends\\n'\n",
      "\n",
      "Next Char Predictions: \n",
      " \"LoreA?y'j6c“FWa'LI63KP2lJ,3hbZsHe!YuTol?P'1pIed?4vbpdSIHWv0SlfMbrLrRz1Yd7mPB48KtTmZ c1!GO!MOsS2M!JEE\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (8, 100, 68)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar loss:  4.219777\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar loss: \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
    "                                                        save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 59s 4s/step - loss: 4.0230\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 57s 4s/step - loss: 3.1412\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.7949\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 2.4911\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 57s 4s/step - loss: 2.3241\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 60s 4s/step - loss: 2.2206\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 2.1435\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 58s 4s/step - loss: 2.0887\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 57s 4s/step - loss: 2.0063\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 1.9438\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 1.8897\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 56s 3s/step - loss: 1.8221\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 62s 4s/step - loss: 1.7553\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 1.6812\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 1.5937\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 1.5195\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 1.4307\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 1.3266\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 1.2340\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 51s 3s/step - loss: 1.1286\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 56s 3s/step - loss: 1.0134\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.8914\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.7747\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.6768\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.5778\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.4993\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.4266\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.3646\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.3176\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.2813\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.2615\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.2345\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.2231\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.1995\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1939\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1809\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.1729\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1607\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1565\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.1442\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.1450\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.1458\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1408\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1419\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1319\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.1235\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.1207\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1213\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.1207\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.1187\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints\\\\ckpt_50'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 256)            17408     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 68)             69700     \n",
      "=================================================================\n",
      "Total params: 4,025,412\n",
      "Trainable params: 4,025,412\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # Evaluate step (generating text using the learning model)\n",
    "    \n",
    "    # Number of characters to generate\n",
    "    num_generate = 1000\n",
    "    \n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    # Empty string to store our results \n",
    "    text_generated = []\n",
    "    \n",
    "    # Low temperatures results in more predictable text\n",
    "    # Higher temperatures results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "    temperature = 1.0\n",
    "    \n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # We pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are like jewels,\n",
      "the work of the hands of a skillful workman.\n",
      "2 Your body is like a rou tr beartimun.\n",
      "5 You have ravished my heart, my sister, my bride.\n",
      "I have gathered my myrngrthan made himself a carriage\n",
      "of the wood of Lebenoverol.\n",
      "He hear on you ouch in through the latch opening.\n",
      "My heart pounded for him, but I did, and I am his.\n",
      "He browses among the lilies,\n",
      "4 You are beautiful, my love.\n",
      "There in the day whon my gore, my beloved, lest I sould kiss you yes, and no one would despise me.\n",
      "2 I would lead you, bringing you into my mother's house,\n",
      "into the chamber of her who conceived me.\n",
      "5 I adjure you, daughters of Jerusalem,\n",
      "becude the lipto my rome.\n",
      "I will take hold of her buthed,\n",
      "that you not stir up, nor ano mountains,\n",
      "skipping on the hills.\n",
      "9 My beloved has gone dovely as Jerusalem,\n",
      "awesome as an army with banners.\n",
      "5 Turn away your eyes from me,\n",
      "for they have over my heart was awake.\n",
      "I will take hold of its fruit.”\n",
      "Lety son or mashe mornimg of the to conceivedy me.\n",
      "They gave you your f\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"You are \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = generate_text(model, start_string=u\"You are \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are beautiful.\n",
      "Your eyes are doves.\n",
      "Beloved\n",
      "16 Behold, you are beautiful, my love, as Tirzah,\n",
      "ther of the mountain of myruhalem,\n",
      "that you not stir up, nor awaken love,\n",
      "until it so desires.\n",
      "8 The voice of my beloved's.\n",
      "mo hear love,\n",
      "my tente.\n",
      "Ther's arm me.\n",
      "11 wis head is like the pmell of Lebanon.\n",
      "12 A locked up garden is my sister, my bride.\n",
      "Beloved\n",
      "2 Let him kiss me with the kisses of his heart.\n",
      "Le is the favorite one ead,\n",
      "for my conceived your mountain of myrrh,\n",
      "to the hill of frime,\n",
      "with me from Lebanon, my beloved, and thighom mount Gidear.\n",
      "2 Your teeth are like a newly shorn flock,\n",
      "which have come up from the washing,\n",
      "whereon a thousand,\n",
      "which If for him whom My soul loves.\n",
      "I held him, and would not let him grome me.\n",
      "Your hair is like a le the shee arf ofly scarcely passed.\n",
      "The vines are in foroushavely.\n",
      "They are right to love you.\n",
      "5 I am dark, but my heart was awake.\n",
      "I will take hold of its fruit.”\n",
      "Let your breasts like its fruit.\n",
      "8 I said, “I will climb up into the palm to me,\n",
      "“Ris\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The most important thing I picked up was the importance of batch size. I was working with a small corpus and using the usual batch_size=128 kept generating incoherent text.\n",
    "* Also, the small size of the corpus makes the generated text a little predictable. I can see two to three word phrases repeated verbatim from the corpus trained on. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
